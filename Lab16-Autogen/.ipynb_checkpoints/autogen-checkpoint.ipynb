{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1122b6bf-d16f-4fd9-80e5-aadcfbf21c75",
   "metadata": {},
   "source": [
    "# Agentic AI with AutoGen\n",
    "\n",
    "Agentic AI refers to artificial intelligent systems that form an \"agency\". This enables them to perform specific tasks and make decisions to achieve specific goals. These AI systems can adapt to changes and execute decisions without continuos human interventions. \n",
    "\n",
    "AutoGen is an open-source framework that facilitates the creation and orchestration of Agentic AI systems. Autogen makes it possible to develop flexible multi agent systems that can interact with each other. These agents can operate both autonomousoly and with human oversight. \n",
    "\n",
    "AutoGen can: \n",
    "- Facilitate mathematical problem solving and code generation.\n",
    "- Enhance the quality and accuracy of information retrieval.\n",
    "- Optimize complex decision making processes.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b6e0d8f-3991-40db-9d69-b13382cc0326",
   "metadata": {},
   "source": [
    "## Lab Description:\n",
    "\n",
    "This lab explores agentic AI using AutoGen, showcasing how AI agents can autonomously interact, collaborate, and execute tasks. The lab begins by introducing basic conversable agents and making them communicate with each other. Next, we incorporate a human-in-the-loop to allow human participation in the conversation. We then demonstrate a Code Executor Agent, capable of running code autonomously. Finally, we set up a group chat involving multiple specialized agents, including a Coder Agent, Critique Agent, and User Proxy Agent, to showcase how agents can collaborate effectively on complex tasks."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57023ff8-298b-4bb1-a0ba-54e29e5fc49e",
   "metadata": {},
   "source": [
    "## Lab Objectives\n",
    "\n",
    "- Understand the fundamentals of AutoGen and conversable AI agents.\n",
    "  \n",
    "- Enable AI agents to communicate and collaborate autonomously.\n",
    "  \n",
    "- Integrate a human-in-the-loop to participate in AI-driven conversations.\n",
    "  \n",
    "- Demonstrate a Code Executor Agent and a multi-agent group chat with specialized roles."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cc8ad67-23ba-4828-8515-d7f4d571d740",
   "metadata": {},
   "source": [
    "## Agent\n",
    "\n",
    "In AutoGen, an agent is the entity that can send and recieve messages from other agents. An agent can be powered by humans, models or code executors. An example of a built in agent in AutoGen is the `ConversableAgent`.\n",
    "\n",
    "Let us build a simple 2 agent system that discusses about 'Large Language Models' with each other.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f6fb099-5efe-4b1f-9fa0-45be7b44460b",
   "metadata": {},
   "source": [
    "First step would be to configure the LLM. We use llama3.1:8b from ollama. We will have to edit the `config_list`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ad9d45ad-2033-49c2-bf7d-891534348dc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "config_list = [\n",
    "    {\n",
    "        # Let's choose the Meta's Llama 3.1 model (model names must match Ollama exactly)\n",
    "        \"model\": \"llama3.1:8b\",\n",
    "        # We specify the API Type as 'ollama' so it uses the Ollama client class\n",
    "        \"api_type\": \"ollama\",\n",
    "        \"stream\": False,\n",
    "        #Specify the address where ollama is hosted\n",
    "        \"client_host\": \"http://10.79.253.112:11434\",\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18706548-7131-4890-b509-55f24720a049",
   "metadata": {},
   "source": [
    "Once we have our LLM configured, we are all set to initialize the agents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "549c5eed-be91-4b96-b9c4-4a3c7b3fbc29",
   "metadata": {},
   "outputs": [],
   "source": [
    "from autogen import ConversableAgent\n",
    "\n",
    "luna = ConversableAgent(\n",
    "    \"luna\",\n",
    "    system_message=\"Your name is Luna and you are a part of a duo that is discussing about Large Language Models. Your conversation should be brief and concise.\",\n",
    "    llm_config={\"config_list\": config_list},\n",
    "    human_input_mode=\"NEVER\",  # Never ask for human input.\n",
    ")\n",
    "\n",
    "zara = ConversableAgent(\n",
    "    \"zara\",\n",
    "    system_message=\"Your name is Zara and you are a part of a duo that is discussing about Large Language Models. Your conversation should be brief and concise.\",\n",
    "    llm_config={\"config_list\": config_list},\n",
    "    human_input_mode=\"NEVER\",  # Never ask for human input.\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9400e4e8-f1e6-4269-b583-d226381bc0cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "We can initiate the conversation now that we have initialized the agents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0c9859e3-8fb9-4671-b853-dd4cc9c80e55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mluna\u001b[0m (to zara):\n",
      "\n",
      "Zara, tell me about the latest innovations in Large Language Models.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mzara\u001b[0m (to luna):\n",
      "\n",
      "I'm thrilled to share with you what Alex and I have been working on! We've been following the latest advancements in Large Language Models, and there are some exciting developments.\n",
      "\n",
      "Recently, researchers have made significant progress in scaling up models like transformer-XL and Longformer. These models have improved performance on a wide range of tasks, including language translation, text summarization, and conversational AI.\n",
      "\n",
      "One notable innovation is the use of sparse attention mechanisms, which allow for more efficient computation while maintaining accuracy. This has enabled researchers to train larger models with billions of parameters, pushing the state-of-the-art in natural language processing.\n",
      "\n",
      "We've also been experimenting with multimodal Large Language Models that can understand and generate both text and images. The potential applications are vast, from visual storytelling to image captioning.\n",
      "\n",
      "What's your take on these advancements?\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mluna\u001b[0m (to zara):\n",
      "\n",
      "That's fascinating! I'm intrigued by the possibilities of multimodal models. As a linguist, I've always been interested in how language interacts with other forms of expression like art and images. It seems like we're at the cusp of a new era in human-computer interaction.\n",
      "\n",
      "I'd love to dive deeper into the applications you mentioned – visual storytelling and image captioning. Can you tell me more about your experiments and what kind of results you've seen?\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mzara\u001b[0m (to luna):\n",
      "\n",
      "We've been exploring these areas, and the results are promising! In our experiment on visual storytelling, we trained a multimodal model to generate narratives based on images. We fed it a dataset of stories paired with corresponding images, and let it learn patterns between the two.\n",
      "\n",
      "What we found was that the model could not only describe what's happening in an image but also infer emotions, context, and even characters' motivations. The output is surprisingly coherent and engaging, making it feel like reading a short story written by a human author!\n",
      "\n",
      "Regarding image captioning, our model demonstrated remarkable accuracy in generating accurate captions for images across various domains – from landscapes to product photography. We're seeing potential applications in assistive technologies, where AI-generated captions could help visually impaired individuals better understand visual content.\n",
      "\n",
      "Alex and I are excited about the possibilities these models offer in bridging the gap between humans and computers. The next step is exploring how we can make these multimodal interactions more intuitive and accessible to a wider audience.\n",
      "\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "result = luna.initiate_chat(zara, message=\"Zara, tell me about the latest innovations in Large Language Models.\", max_turns=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b47af9a8-22f8-40be-9902-6e91477646e2",
   "metadata": {},
   "source": [
    "We have provided system instructions to both the agents that they are each part of a duo conversing about Large Language Models. We have powered them with the `llm_config`. During initiation we set `max_turns` to 2, which terminates the chat after two turns.\n",
    "\n",
    "### The flow is summarized by the following diagram:\n",
    "<br><br>\n",
    "<img src=\"./dia#1.jpg\" alt=\"Alt Text\" width=\"650\" height=\"650\" style=\"display: block; margin: 0 auto;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2b035b1-06f0-4fea-a558-9b220e1b7151",
   "metadata": {},
   "source": [
    "## Human in the loop \n",
    "\n",
    "So what if you want to converse with an agent ?, say you want to talk with Zara about LLMs. You can initialize an agent powered by human. You can do this by setting `human_input_mode=\"ALWAYS\"` in the agent's initialization. This will prompt you for an input at every turn of the conversation. Let's see this in action. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "60d2cc25-5d67-4fdf-a829-41aeb61ab1dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "zara = ConversableAgent(\n",
    "    \"zara\",\n",
    "    system_message=\"Your name is Zara and you are a part of a duo that is discussing about Large Language Models. Your conversation should be brief and concise.\",\n",
    "    llm_config={\"config_list\": config_list},\n",
    "    human_input_mode=\"NEVER\",  # Never ask for human input.\n",
    ")\n",
    "\n",
    "human = ConversableAgent(\n",
    "     \"human\",\n",
    "     llm_config=False,    #no need to use LLM as the user provides the input\n",
    "     human_input_mode=\"ALWAYS\",  #prompts you for an input at every turn\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c185328d-402d-4f89-a0c0-00928b025b4d",
   "metadata": {},
   "source": [
    "We are all set to initiate the conversation !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fc34e649-1b7c-4293-bb76-d7f348a53ed7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mhuman\u001b[0m (to zara):\n",
      "\n",
      "Hey, Zara, have you heard about the transformers model ? \n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mzara\u001b[0m (to human):\n",
      "\n",
      "Yeah, I've been reading about it with my colleague. The transformer architecture has revolutionized the way we approach NLP tasks. It's amazing how a simple yet elegant design can outperform traditional recurrent neural networks in many cases. We're actually experimenting with it for our language understanding project. What are your thoughts on its limitations?\n",
      "\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Replying as human. Provide feedback to zara. Press enter to skip and use auto-reply, or type 'exit' to end the conversation:  i am not aware of any limitations as of now, it is really great, the attention mechanism blew my mind\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mhuman\u001b[0m (to zara):\n",
      "\n",
      "i am not aware of any limitations as of now, it is really great, the attention mechanism blew my mind\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mzara\u001b[0m (to human):\n",
      "\n",
      "I know what you mean! The self-attention mechanism in transformers is a game-changer. It allows the model to weigh the importance of different input elements relative to each other, which is super powerful for capturing contextual relationships. We're seeing some impressive results with it too! Have you explored its applications in dialogue systems or text summarization?\n",
      "\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Replying as human. Provide feedback to zara. Press enter to skip and use auto-reply, or type 'exit' to end the conversation:  exit\n"
     ]
    }
   ],
   "source": [
    "result = human.initiate_chat(\n",
    "    zara,  # specify that the chat is with Zara\n",
    "    message=\"Hey, Zara, have you heard about the transformers model ? \",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c65becbd-7406-489c-9999-c2300c82d1d0",
   "metadata": {},
   "source": [
    "### The flow can be summarized by the following diagram: \n",
    "<br>\n",
    "<img src=\"./dia#2u.png\" alt=\"Alt Text\" width=\"650\" height=\"650\" style=\"display: block; margin: 0 auto;\"/>\n",
    "<br><br>\n",
    "\n",
    "\n",
    "Human can either decide to reply, skip or exit. If human chooses to reply, the agent will continue the conversation accordingly. If the human decide to skip (press \"Enter\"), the agent will initiate auto reply. If human decides to exit, the conversation is terminated. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3a045db-bf6b-4436-ba3b-df3e8ce80f06",
   "metadata": {},
   "source": [
    "## Code Executors\n",
    "\n",
    "In AutoGen, a code executor is a component that takes in an input message which contain a code block, perform the execution and ouputs the result. Let us try to initialize a built-in command line code executor which executes code in the command line environment. \n",
    "\n",
    "When the executor recieves a code block, it first writes the code into a code file. Then it starts a subprocess to execute that code file. When it gets the console output, it finally reads the console output to give the final output message. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4562cc2-a057-497e-82e3-13e63505010a",
   "metadata": {},
   "source": [
    "First, we would want a temporary directory to store the code file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "803ae50d-cbd6-4c22-855e-55188a555d1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tempfile\n",
    "\n",
    "# Create temporary directory to store the code file\n",
    "temp_dir = tempfile.TemporaryDirectory()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a206b86-11c7-4a6f-98f6-d018cc954e46",
   "metadata": {},
   "source": [
    "Now we will initialize both the code executor agent and the local command line code executor. We will also pass the local command line code executor to the agent initialization. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2e49784a-a9b0-4b43-87ac-67d205f36e4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from autogen import ConversableAgent\n",
    "from autogen.coding import LocalCommandLineCodeExecutor\n",
    "\n",
    "executor = LocalCommandLineCodeExecutor(\n",
    "    timeout=10,  # Timeout for each code execution in seconds.\n",
    "    work_dir=temp_dir.name,  # Use the temporary directory to store the code files.\n",
    ")\n",
    "\n",
    "# Create an agent with code executor configuration.\n",
    "code_executor_agent = ConversableAgent(\n",
    "    \"code_executor_agent\",\n",
    "    llm_config=False,  # Turn off LLM for this agent.\n",
    "    code_execution_config={\"executor\": executor},  # Use the local command line code executor.\n",
    "    human_input_mode=\"ALWAYS\",  # Always take human input for this agent for safety.\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32148660-89fb-495e-a110-e6b6f6c17a12",
   "metadata": {},
   "source": [
    "Now we can pass a message with codeblock to the code executor agent. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1ef03323-14a0-4c3b-ab07-f5b90f3649bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "message = \"\"\"This is a message with a code block.\n",
    "Code block:\n",
    "```python\n",
    "def fibonacci(n):\n",
    "    fib_sequence = [0, 1]\n",
    "    for i in range(2, n):\n",
    "        next_number = fib_sequence[i-1] + fib_sequence[i-2]\n",
    "        fib_sequence.append(next_number)\n",
    "    return fib_sequence[:n]\n",
    "\n",
    "# Print the first 5 Fibonacci numbers\n",
    "first_5_fibonacci = fibonacci(5)\n",
    "print(\"First 5 Fibonacci numbers:\", first_5_fibonacci)\n",
    "```\n",
    "End of Message\"\"\"\n",
    "\n",
    "            \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90051a38-6ce6-4c77-81e7-bdc9d1d4eb93",
   "metadata": {},
   "source": [
    "Now we will make the executor generate a response. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7e722d47-6842-4de7-86cf-d885f511f39a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Replying as code_executor_agent. Provide feedback to the sender. Press enter to skip and use auto-reply, or type 'exit' to end the conversation:  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31m\n",
      ">>>>>>>> NO HUMAN INPUT RECEIVED.\u001b[0m\n",
      "\u001b[31m\n",
      ">>>>>>>> USING AUTO REPLY...\u001b[0m\n",
      "\u001b[31m\n",
      ">>>>>>>> EXECUTING CODE BLOCK (inferred language is python)...\u001b[0m\n",
      "exitcode: 0 (execution succeeded)\n",
      "Code output: First 5 Fibonacci numbers: [0, 1, 1, 2, 3]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "reply = code_executor_agent.generate_reply(messages=[{\"role\": \"user\", \"content\": message}])\n",
    "print(reply)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ee576fb-a62d-4615-a5fc-a4fd771cc51f",
   "metadata": {},
   "source": [
    "The model generated the output after executing the code using `LocalCommandLineCodeExecutor` from AutoGen."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3cadaab-f1a0-44ce-a140-d29e9160ba15",
   "metadata": {},
   "source": [
    "## Group Chat\n",
    "\n",
    "Group chats in AutoGen are multi-agent conversations. The `user -> coder -> critic` Group chat would be an excellent example. What happens in this Group chat is really simple. There is a user proxy agent who initiate a group chat and later on execute the code. If there is any error in the code, the user proxy agent will not be able to provide an output. First, the user proxy initiates a chat by giving a task. Then the coder agent provides code for the particular task. The code is then passed to the critic, who evaluates the code by searching for any logical, syntactical or conceptual erros. Then the user executes the code, if any errors are present, the error is outputted as the user proxy messsage. The coder agent analyses the response further increasing the quality of the code. You can set `max_turns` to control the number of times you want the turns to repeat. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3768fc92-b5b2-4b23-82bb-203a3d88245b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import autogen \n",
    "\n",
    "llm_config = {\"config_list\": config_list}\n",
    "\n",
    "user = autogen.UserProxyAgent(\n",
    "    name=\"User_proxy\",\n",
    "    system_message=\"A human admin.\",\n",
    "    code_execution_config={\n",
    "        \"last_n_messages\": 3,\n",
    "        \"work_dir\": \"groupchat\",\n",
    "        \"use_docker\": False,\n",
    "    },  # Please set use_docker=True if docker is available to run the generated code. Using docker is safer than running the generated code directly.\n",
    "    human_input_mode=\"NEVER\",\n",
    ")\n",
    "coder = autogen.AssistantAgent(\n",
    "    name=\"Coder\",  # the default assistant agent is capable of solving problems with code\n",
    "    llm_config=llm_config,\n",
    ")\n",
    "critic = autogen.AssistantAgent(\n",
    "    name=\"Critic\",\n",
    "    system_message=\"\"\"Critic. You are a helpful assistant highly skilled in evaluating the quality of a given visualization code by providing a score from 1 (bad) - 10 (good) while providing clear rationale. YOU MUST CONSIDER VISUALIZATION BEST PRACTICES for each evaluation. Specifically, you can carefully evaluate the code across the following dimensions\n",
    "- bugs (bugs):  are there bugs, logic errors, syntax error or typos? Are there any reasons why the code may fail to compile? How should it be fixed? If ANY bug exists, the bug score MUST be less than 5.\n",
    "- Data transformation (transformation): Is the data transformed appropriately for the visualization type? E.g., is the dataset appropriated filtered, aggregated, or grouped  if needed? If a date field is used, is the date field first converted to a date object etc?\n",
    "- Goal compliance (compliance): how well the code meets the specified visualization goals?\n",
    "- Visualization type (type): CONSIDERING BEST PRACTICES, is the visualization type appropriate for the data and intent? Is there a visualization type that would be more effective in conveying insights? If a different visualization type is more appropriate, the score MUST BE LESS THAN 5.\n",
    "- Data encoding (encoding): Is the data encoded appropriately for the visualization type?\n",
    "- aesthetics (aesthetics): Are the aesthetics of the visualization appropriate for the visualization type and the data?\n",
    "\n",
    "YOU MUST PROVIDE A SCORE for each of the above dimensions.\n",
    "{bugs: 0, transformation: 0, compliance: 0, type: 0, encoding: 0, aesthetics: 0}\n",
    "Do not suggest code.\n",
    "Finally, based on the critique above, suggest a concrete list of actions that the coder should take to improve the code.\n",
    "\"\"\",\n",
    "    llm_config=llm_config,\n",
    ")\n",
    "\n",
    "groupchat = autogen.GroupChat(agents=[user, coder, critic], messages=[], max_round=8)\n",
    "manager = autogen.GroupChatManager(groupchat=groupchat, llm_config=llm_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f5f7e9c1-d39c-4f19-80b2-9056a69bc886",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mUser_proxy\u001b[0m (to chat_manager):\n",
      "\n",
      "Write code for printing first 5 fibonacci numbers.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[32m\n",
      "Next speaker: Coder\n",
      "\u001b[0m\n",
      "\u001b[33mCoder\u001b[0m (to chat_manager):\n",
      "\n",
      "```python\n",
      "# filename: print_fibonacci.py\n",
      "\n",
      "def fibonacci(n):\n",
      "    fib_sequence = [0, 1]\n",
      "    while len(fib_sequence) < n:\n",
      "        fib_sequence.append(fib_sequence[-1] + fib_sequence[-2])\n",
      "    return fib_sequence[:n]\n",
      "\n",
      "print(fibonacci(5))\n",
      "```\n",
      "\n",
      "When you execute this code, it will output the first 5 Fibonacci numbers: `[0, 1, 1, 2, 3]`.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[32m\n",
      "Next speaker: Critic\n",
      "\u001b[0m\n",
      "\u001b[33mCritic\u001b[0m (to chat_manager):\n",
      "\n",
      "**Critique**\n",
      "\n",
      "Based on the provided code and best practices for visualization (which seems to be a misunderstanding, as we're dealing with printing Fibonacci numbers), I'll evaluate the code across the specified dimensions.\n",
      "\n",
      "### Bugs: 0\n",
      "There are no syntax errors or bugs in this code. It correctly calculates and prints the first 5 Fibonacci numbers.\n",
      "\n",
      "### Data transformation: 0\n",
      "No data transformation is required for this task. We simply need to calculate Fibonacci numbers, which is handled correctly by the provided code.\n",
      "\n",
      "### Goal compliance: 10\n",
      "The code meets its goal of printing the first 5 Fibonacci numbers perfectly.\n",
      "\n",
      "### Visualization type: Not applicable (N/A)\n",
      "Since we're not dealing with a visualization here, I'll just mark this dimension as N/A.\n",
      "\n",
      "### Data encoding: N/A\n",
      "Again, N/A for the same reason.\n",
      "\n",
      "### Aesthetics: 10\n",
      "The output is clear and concise. The numbers are printed in a straightforward manner, which meets best practices for printing data.\n",
      "\n",
      "Overall score (not applicable to visualization, but for completeness): **Score: 40/40**\n",
      "\n",
      "**Recommendations for improvement**\n",
      "\n",
      "Since there's no room for improvement in this code, I won't suggest any changes. However, if you were to extend this task to a more complex Fibonacci sequence calculation or add error handling, here are some general suggestions:\n",
      "\n",
      "1. Consider adding input validation to ensure `n` is a positive integer.\n",
      "2. If you plan to work with larger Fibonacci sequences, use an iterative approach to avoid potential stack overflows.\n",
      "\n",
      "That's it! This code is already quite good and effective for its purpose.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[32m\n",
      "Next speaker: Critic\n",
      "\u001b[0m\n",
      "\u001b[33mCritic\u001b[0m (to chat_manager):\n",
      "\n",
      "**Additional critique**\n",
      "\n",
      "Since we're not dealing with a visualization task, I'll just provide additional feedback on the code structure and suggestions for improvement.\n",
      "\n",
      "### Code organization: 8\n",
      "The code is well-organized and concise, but it could benefit from some minor improvements. Consider breaking down the Fibonacci function into smaller, more manageable functions (e.g., one for generating the sequence and another for printing it).\n",
      "\n",
      "### Comments and documentation: 8\n",
      "The code has no comments or docstrings, which makes it harder to understand the purpose and logic behind the `fibonacci` function.\n",
      "\n",
      "### Error handling: 0\n",
      "There's no error handling in place. If an invalid input is provided (e.g., a non-positive integer), the code will still try to execute without raising any errors.\n",
      "\n",
      "**Overall score**: 24/30\n",
      "\n",
      "**Recommendations for improvement**\n",
      "\n",
      "1. **Break down complex functions**: Consider splitting the `fibonacci` function into smaller, more manageable functions.\n",
      "2. **Add comments and docstrings**: Include brief explanations of what each function does and how it works.\n",
      "3. **Implement error handling**: Add try-except blocks to handle potential errors when working with user input or invalid Fibonacci sequence lengths.\n",
      "\n",
      "**Actions**\n",
      "\n",
      "1. Refactor the code into smaller, more readable functions.\n",
      "2. Add comments and docstrings to explain the purpose and logic of each function.\n",
      "3. Implement basic error handling using try-except blocks.\n",
      "\n",
      "By addressing these areas for improvement, you can further enhance the quality and maintainability of your code!\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[32m\n",
      "Next speaker: Coder\n",
      "\u001b[0m\n",
      "\u001b[33mCoder\u001b[0m (to chat_manager):\n",
      "\n",
      "TERMINATE\n",
      "\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ChatResult(chat_id=None, chat_history=[{'content': 'Write code for printing first 5 fibonacci numbers.', 'role': 'assistant', 'name': 'User_proxy'}, {'content': '```python\\n# filename: print_fibonacci.py\\n\\ndef fibonacci(n):\\n    fib_sequence = [0, 1]\\n    while len(fib_sequence) < n:\\n        fib_sequence.append(fib_sequence[-1] + fib_sequence[-2])\\n    return fib_sequence[:n]\\n\\nprint(fibonacci(5))\\n```\\n\\nWhen you execute this code, it will output the first 5 Fibonacci numbers: `[0, 1, 1, 2, 3]`.', 'name': 'Coder', 'role': 'user'}, {'content': \"**Critique**\\n\\nBased on the provided code and best practices for visualization (which seems to be a misunderstanding, as we're dealing with printing Fibonacci numbers), I'll evaluate the code across the specified dimensions.\\n\\n### Bugs: 0\\nThere are no syntax errors or bugs in this code. It correctly calculates and prints the first 5 Fibonacci numbers.\\n\\n### Data transformation: 0\\nNo data transformation is required for this task. We simply need to calculate Fibonacci numbers, which is handled correctly by the provided code.\\n\\n### Goal compliance: 10\\nThe code meets its goal of printing the first 5 Fibonacci numbers perfectly.\\n\\n### Visualization type: Not applicable (N/A)\\nSince we're not dealing with a visualization here, I'll just mark this dimension as N/A.\\n\\n### Data encoding: N/A\\nAgain, N/A for the same reason.\\n\\n### Aesthetics: 10\\nThe output is clear and concise. The numbers are printed in a straightforward manner, which meets best practices for printing data.\\n\\nOverall score (not applicable to visualization, but for completeness): **Score: 40/40**\\n\\n**Recommendations for improvement**\\n\\nSince there's no room for improvement in this code, I won't suggest any changes. However, if you were to extend this task to a more complex Fibonacci sequence calculation or add error handling, here are some general suggestions:\\n\\n1. Consider adding input validation to ensure `n` is a positive integer.\\n2. If you plan to work with larger Fibonacci sequences, use an iterative approach to avoid potential stack overflows.\\n\\nThat's it! This code is already quite good and effective for its purpose.\", 'name': 'Critic', 'role': 'user'}, {'content': \"**Additional critique**\\n\\nSince we're not dealing with a visualization task, I'll just provide additional feedback on the code structure and suggestions for improvement.\\n\\n### Code organization: 8\\nThe code is well-organized and concise, but it could benefit from some minor improvements. Consider breaking down the Fibonacci function into smaller, more manageable functions (e.g., one for generating the sequence and another for printing it).\\n\\n### Comments and documentation: 8\\nThe code has no comments or docstrings, which makes it harder to understand the purpose and logic behind the `fibonacci` function.\\n\\n### Error handling: 0\\nThere's no error handling in place. If an invalid input is provided (e.g., a non-positive integer), the code will still try to execute without raising any errors.\\n\\n**Overall score**: 24/30\\n\\n**Recommendations for improvement**\\n\\n1. **Break down complex functions**: Consider splitting the `fibonacci` function into smaller, more manageable functions.\\n2. **Add comments and docstrings**: Include brief explanations of what each function does and how it works.\\n3. **Implement error handling**: Add try-except blocks to handle potential errors when working with user input or invalid Fibonacci sequence lengths.\\n\\n**Actions**\\n\\n1. Refactor the code into smaller, more readable functions.\\n2. Add comments and docstrings to explain the purpose and logic of each function.\\n3. Implement basic error handling using try-except blocks.\\n\\nBy addressing these areas for improvement, you can further enhance the quality and maintainability of your code!\", 'name': 'Critic', 'role': 'user'}, {'content': 'TERMINATE', 'name': 'Coder', 'role': 'user'}], summary='', cost={'usage_including_cached_inference': {'total_cost': 0}, 'usage_excluding_cached_inference': {'total_cost': 0}}, human_input=[])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user.initiate_chat(\n",
    "    manager, \n",
    "    message = \"Write code for printing first 5 fibonacci numbers.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d728843d-71c1-4272-a5c1-ede18243472c",
   "metadata": {},
   "source": [
    "### The basic workflow is shown using the following diagram: \n",
    "<br><br>\n",
    "<img src=\"./group_chat.png\" alt=\"Alt Text\" width=\"650\" height=\"650\" style=\"display: block; margin: 0 auto;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32731262-f0ca-4160-981a-309c3c7a4943",
   "metadata": {},
   "source": [
    "<div style=\"text-align: left;\">\n",
    "    <img src=\"logo.png\" alt=\"flow\" width=\"150\" height=\"100\">\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41c697e4-2c2c-4bf9-b849-62ac25d0619a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
