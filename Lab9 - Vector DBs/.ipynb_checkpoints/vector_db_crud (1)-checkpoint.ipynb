{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d828e1c9-0948-47cb-9360-01ac2f6c5633",
   "metadata": {},
   "source": [
    "# CRUD Operations on Vector Databases \n",
    "\n",
    "## Lab Description:\n",
    "\n",
    "In this lab, participants will learn how to perform CRUD (Create, Read, Update, Delete) operations on a vector database using ChromaDB. We begin by introducing word embeddings and how they transform text into numerical representations. Next, we create an **in-memory Chroma vector store** and add text data to it. We then perform a similarity search to retrieve relevant information based on embeddings. After that, we explore how to remove, update, and delete elements from the vector store.\n",
    "\n",
    "## Lab Objectives:\n",
    "\n",
    "After completing this lab, participants will be able to:\n",
    "\n",
    "- Understand and apply the concept of word embeddings.\n",
    "- Create and manage a Chroma in-memory vector store.\n",
    "- Modify vector data by updating and deleting stored elements.\n",
    "- Perform CRUD operations (Create, Read, Update, Delete) on a vector database..\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91464dc5-2a31-4796-89cf-0139d7d610f8",
   "metadata": {},
   "source": [
    "## VECTOR EMBEDDINGS:\n",
    "\n",
    "Vector embeddings are basically numerical representations of objects like text, audio or images. This enables us to capture their semantic meanings or their relationships with one another. Making it easier to perform similarity searches and classifications on our dataset. \n",
    "\n",
    "So, how exactly are sentences converted into numbers ? \n",
    "\n",
    "Well, first, a sentence is broken down into smaller chunks called \"tokens\". Each token is then mapped to a numerical representation using various methods. Some of which are:\n",
    "\n",
    "Word Embeddings: Certain techniques like \"Word2Vec\" converts each token into vectors based on its context, which provides their semantic relationships in a given context.\n",
    "\n",
    "Transformers: Models like BERT uses deep learning to generate embeddings. Each tokens vector would then reflect its meaning in a context. \n",
    "\n",
    "So let's see how vector embeddings are implemented. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea273c81-0c48-4a90-a66d-13c3e8215412",
   "metadata": {},
   "source": [
    "HuggingFace provides a lot of sentence transformers like \"all-MiniLM-L6-v2\" and \"all-mpnet-base-v2\". We can leverage these transformers to generate embeddings for our sentences. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "945e05c3-4d9b-451f-acc2-375f5f7d46a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_huggingface.embeddings import HuggingFaceEmbeddings #importing the HuggingFaceEmbeddings class from LangChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0e946329-e614-477c-9eb1-7d852d106756",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/jupyter/lab7/langchain_env/lib/python3.12/site-packages/sentence_transformers/cross_encoder/CrossEncoder.py:13: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from tqdm.autonotebook import tqdm, trange\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.04895174130797386, -0.03986189886927605, -0.021562783047556877]\n"
     ]
    }
   ],
   "source": [
    "embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-mpnet-base-v2\") #loads the model \"all-mpnet-base-v2\" from HuggingFace\n",
    "text = \"This is a test document.\"                                                        #A sample sentence\n",
    "query_result = embeddings.embed_query(text)  \n",
    "#prinlen #embed_query() method takes in a string as the input and computes query embeddings using a HuggingFace transformer model.\n",
    "print(query_result[:3])                                                                  #prints the first 3 elements of the vector. For most models like BERT each token is converted into a vector with 768 values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "866648d4-0940-4d32-bc4d-3e5898e33d9a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "768"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(query_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8201341-4a1a-47bf-85af-d999a3b2b333",
   "metadata": {},
   "source": [
    "These are the first 3 elements of the word embedding that we generated."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a83ea3d3-8caa-4fb3-a504-18ad64194b8a",
   "metadata": {},
   "source": [
    "## VECTOR DATABASES\n",
    "\n",
    "We would need a system to manage and query high-dimensional vector embeddings like the one which we just generated. This is where a vector database comes into play. A vector database lets us store large volumes of vector embeddings. This enables efficient storage, indexing and retrieval. There are many popular vector databases like ChromaDB, FAISS and Weaviate."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d09505e-27e5-40af-8e6c-51921ff69d1a",
   "metadata": {},
   "source": [
    "## CREATING A VECTOR DATABASE WITH CHROMADB:\n",
    "\n",
    "Lets see how we can create a vector database using Chroma DB. Note how we use the method discussed above to first convert our text into its vector embedding before adding to the vector DB. We use `sentence-transformers/all-mpnet-base-v2` from huggingface as our Embedding Model. This Model is responsible for converting our text collection into vector representations.\n",
    "\n",
    "<div style=\"text-align: center;\">\n",
    "    <img src=\"flow.png\" alt=\"flow\" width=\"800\" height=\"660\">\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "982f1d96-d7f3-4dfb-9840-ce8f9b474016",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_chroma import Chroma  #langchain_chroma is the official langchain framework for chromadb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5b0dee95-595e-442c-90b1-47559d719276",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-mpnet-base-v2\") #loading the embedding model\n",
    "text_collection = [                                                                      #Sample text sets to be added to the vector db\n",
    "    \"I love cats\", \n",
    "    \"I love programming\",\n",
    "    \"I love computers\", \n",
    "    \"I like to eat burgers\"\n",
    "]\n",
    "\n",
    "vector_store = Chroma.from_texts(texts=text_collection, embedding=embeddings)            #creating a vector database from texts, the parameters are the list of text and the embedding model\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dddfa13-47c5-4ea0-9a3b-051808b5e977",
   "metadata": {},
   "source": [
    "Now that the vector store is created, we can perform operations like similarity search on the vector database. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0170e4ff-da76-4328-8f35-26f3a3aa2d6e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(Document(metadata={}, page_content='I love computers'), 0.8973314762115479),\n",
       " (Document(metadata={}, page_content='I love programming'),\n",
       "  0.9493520259857178)]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"I love machine learning\"                                    #The query to perform similarity search on the vector db\n",
    "\n",
    "result = vector_store.similarity_search_with_score(query=query, k=2) #similarity_search_with_score method returns the list of documents most similar to the given query. The parameter k=2 implies it return the 2 most similar docs, it also returns a score, lower score indicating more similarity\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e7ae314-d0f1-45ed-a4c0-d32daaf1ebd3",
   "metadata": {},
   "source": [
    "This returns the two most similar sentenses to the query, the score is cosine distance in float for each. Lower score represents more similarity. \n",
    "\n",
    "\n",
    "Cosine distance measures the similarity between two vectors by calculating the cosine of the angle between them in a multi-dimensional space. In NLP, it is commonly used to determine how similar two text embeddings are, with a smaller cosine distance indicating greater similarity."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "124313c1-550b-4f7f-a322-e75992ded980",
   "metadata": {},
   "source": [
    "We can also store a piece of text and associated metadata as a document and then add it to the vector db using document class from the langchain_core library.\n",
    "\n",
    "In Python, a UUID (Universally Unique Identifier) is a special 128-bit number that helps identify things uniquely. The uuid module allows you to create these identifiers easily, ensuring they won't be duplicated. This helps us to generate unique ids for each document so that querying them later would be a simple task. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cee79176-99d2-4a8b-b4f7-80a0d49721e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.documents import Document\n",
    "from uuid import uuid4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ece07e14-d9c1-4f9e-80f1-3d1b374dd70d",
   "metadata": {},
   "outputs": [],
   "source": [
    "document1 = Document(\n",
    "    page_content=\"I love cats\",     #stores the text along with an associated metadata\n",
    "    metadata={\"source\":\"tweet\"},\n",
    "    id=1                            #you can also add an optional id to distinguish each document especially in a really large dataset\n",
    ")\n",
    "\n",
    "document2 = Document(\n",
    "    page_content=\"I love programming\",     \n",
    "    metadata={\"source\":\"tweet\"},\n",
    "    id=2\n",
    ")\n",
    "\n",
    "document3 = Document(\n",
    "    page_content=\"Vector Databases Enhance Search and Retrieval for AI Applications.\",     \n",
    "    metadata={\"source\":\"news\"},\n",
    "    id=3\n",
    ")\n",
    "\n",
    "document4 = Document(\n",
    "    page_content=\"Machine Learning Drives Innovation and Efficiency Across Sectors.\",     \n",
    "    metadata={\"source\":\"news\"},\n",
    "    id=4\n",
    ")\n",
    "\n",
    "document = [                        #all documents are now a single list \n",
    "    document1,\n",
    "    document2,\n",
    "    document3,\n",
    "    document4\n",
    "]\n",
    "\n",
    "uuids = [str(uuid4()) for _ in range(len(document))]  #Generates a random uuid for each document in our list.\n",
    "# print(uuids)\n",
    "# document"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d78e2dc2-235b-4138-a22e-3266cec6fae2",
   "metadata": {},
   "source": [
    "we can now create a vector database to store these documents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4a89c86a-bd8c-43a6-aff0-5ab5443d2047",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['6b96740a-74d1-48e0-9dbe-75484495caca', '6e7863e1-47c7-4c6c-95c4-bf2e4eb920a8', 'f399256d-7fe5-49ac-bb6f-53fdd16a468b', 'cdd6ddd4-920c-4a6d-9490-01e9523cb9c1']\n"
     ]
    }
   ],
   "source": [
    "print(uuids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "460b4eda-4945-4478-a14c-e1656ad108f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-mpnet-base-v2\")  #import the embedding model\n",
    "\n",
    "vector_store = Chroma(\n",
    "    collection_name=\"docuemnt_collection\",    #the name of your collection \n",
    "    embedding_function=embeddings             #specify the embedding function \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5538a2e0-81aa-41d8-8470-3ccc7afaa3a3",
   "metadata": {},
   "source": [
    "To add our documents into the vector store, we can use the add_document() method. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7a1b5448-01a2-489f-9054-7b9dec977dba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['6b96740a-74d1-48e0-9dbe-75484495caca',\n",
       " '6e7863e1-47c7-4c6c-95c4-bf2e4eb920a8',\n",
       " 'f399256d-7fe5-49ac-bb6f-53fdd16a468b',\n",
       " 'cdd6ddd4-920c-4a6d-9490-01e9523cb9c1']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector_store.add_documents(documents=document, ids=uuids)  #this will add documents into the vector db with the given embedding."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e754563-bb83-480f-87f7-b3b938802b83",
   "metadata": {},
   "source": [
    "## RETRIEVAL USING SIMILARITY SEARCH"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71484bc9-8bf0-430c-a39d-a7416de699b7",
   "metadata": {},
   "source": [
    "Now that we have the vector database, we can perform similarity searches on them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8e22d549-517a-4085-98cf-d53f63fc7529",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': 'news'}, page_content='Machine Learning Drives Innovation and Efficiency Across Sectors.'),\n",
       " Document(metadata={'source': 'news'}, page_content='Vector Databases Enhance Search and Retrieval for AI Applications.')]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"Deep learning powers AI by helping machines learn from data.\"\n",
    "\n",
    "result = vector_store.similarity_search(\n",
    "    query=query,              #the query to be searched\n",
    "    k=2,                      #returns the 2 most similar documents\n",
    "    filter={\"source\":\"news\"}  #filters documents based on the metadata. [optional]\n",
    "   )\n",
    "\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa0e9031-8873-4e0e-9e7c-d2c7071827d1",
   "metadata": {},
   "source": [
    "This returns the two most similar documents, filtered by the metadata we provided. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dbe0daf-b75f-4850-b8d4-e4644d2c78f5",
   "metadata": {},
   "source": [
    "## UPDATE VECTOR DB\n",
    "\n",
    "We can update the vector database with the update_document() method. It requires the id of the document to be updated and the new document. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f02a9267-87dd-47c3-b4c6-ef7c63aaf460",
   "metadata": {},
   "outputs": [],
   "source": [
    "updated_document_1 = Document(            #The new document\n",
    "    page_content=\"I really love dogs\",\n",
    "    metadata={\"source\": \"tweet\"},\n",
    "    id=1,\n",
    ")\n",
    "\n",
    "vector_store.update_document(document_id=uuids[0], document=updated_document_1)   #The update_document() method updates the vector db. Note how we access the element with uuid[0], which is the id we generated for the first element."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "82a37b17-7fc0-49f3-8f81-c94d809d8b00",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ids': ['95f10471-c84b-4eb6-beae-3f61d13a0df8'],\n",
       " 'embeddings': None,\n",
       " 'metadatas': [{'source': 'tweet'}],\n",
       " 'documents': ['I really love dogs'],\n",
       " 'uris': None,\n",
       " 'data': None,\n",
       " 'included': ['metadatas', 'documents']}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector_store.get(ids=uuids[0]) #the .get() method fetches the vector db elements by their ids"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a588e9b-d409-469b-8687-8b58cabda5bc",
   "metadata": {},
   "source": [
    "We can now do a similarity search on the updated vector database. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "90ed1327-bcb5-44a4-b8eb-27cf69068c0d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': 'tweet'}, page_content='I really love dogs'),\n",
       " Document(metadata={'source': 'tweet'}, page_content='I love programming')]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"I love pets.\" #The query for our new similarity search\n",
    "\n",
    "result = vector_store.similarity_search(query=query, k=2, filter={\"source\":\"tweet\"})  #performs a similarity search with the given query and fetches the 2 most similar documents, with a filter. \n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd5442f7-4560-420a-9260-9ad25563fe0c",
   "metadata": {},
   "source": [
    "We can see that the similarity search pulled the updated document. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d6bf261-9771-45ba-8a23-d62403523249",
   "metadata": {},
   "source": [
    "## DELETING FROM THE VECTOR DB\n",
    "\n",
    "The delete() method deletes vector db elements. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "29531645-9441-4281-ad23-b09112482b19",
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_store.delete(ids=uuids[-1])  #this will delete the last element of the vector db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2ad76514-3759-4c25-8237-1b77e1bc4c2f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'e47753de-cbaa-4d1d-aa9a-30fb9fffe984'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "uuids.pop() #removing the id of the deleted element"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d8be3f7c-852e-4cf3-88d7-b612a541998e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ids': ['2bc909ee-83e6-4f89-89ea-5d63c60676d3'],\n",
       " 'embeddings': None,\n",
       " 'metadatas': [{'source': 'news'}],\n",
       " 'documents': ['Vector Databases Enhance Search and Retrieval for AI Applications.'],\n",
       " 'uris': None,\n",
       " 'data': None,\n",
       " 'included': ['metadatas', 'documents']}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector_store.get(ids=uuids[-1]) #fetches the last element in the vector db"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40e07fa7-a27e-4e2e-881c-1f63e6c32d7f",
   "metadata": {},
   "source": [
    "The last element is deleted. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6b77d16-0bd8-46ed-aa96-47fc2ac01f96",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ff340a5-438c-4621-aa4e-a4a2b60dabb2",
   "metadata": {},
   "source": [
    "<div style=\"text-align: left;\">\n",
    "    <img src=\"logo.png\" alt=\"flow\" width=\"150\" height=\"100\">\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2990b855-d0a3-4556-b12c-4f50c8a73d35",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
